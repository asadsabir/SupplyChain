{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- analyze results +\n",
    "- Normalize \n",
    "- add lag\n",
    "- try other models +\n",
    "- tune hyperparameters\n",
    "    - cheby k\n",
    "    - filter out\n",
    "    - nn depth\n",
    "    - nn width\n",
    "    - non-linear filter function\n",
    "    - learning rate\n",
    "    - optimizer\n",
    "    - epochs\n",
    "- try dynamic graph split\n",
    "- incorporate storage_location,product_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pickle.load(open('graphs/graph.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2d = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Delivery To distributor.csv')\n",
    "factory_issue = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Factory Issue.csv')\n",
    "production = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Production .csv')\n",
    "sales_orders = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Sales Order .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "d2d = scaler.fit_transform(d2d.drop('Date',axis=1))\n",
    "factory_issue = scaler.fit_transform(factory_issue.drop('Date',axis=1))\n",
    "sales_orders = scaler.fit_transform(sales_orders.drop('Date',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 41)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2d[:0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = production.drop('Date',axis=1).columns\n",
    "for node in G.nodes:\n",
    "    node_mask = [n == node for n in columns] \n",
    "    G.nodes[node]['delivered'] = d2d[:,node_mask]\n",
    "    G.nodes[node]['factory issue'] = factory_issue[:,node_mask]\n",
    "    G.nodes[node]['sales_order'] = sales_orders[:,node_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes['SOS008L02P']['production'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_processed = nx.convert_node_labels_to_integers(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_processed.remove_edges_from([(u,v) for u,v,d in G_processed.edges(data=True) if d['Plant'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr = np.zeros((len(G_processed.edges()),1))\n",
    "\n",
    "for i,e in enumerate(G_processed.edges(data=True)):\n",
    "    # edge_attr[i] = np.array(list(e[2].values()),dtype=float)\n",
    "    edge_attr[i] = list(e[2].values())[0]\n",
    "\n",
    "#edge_attr = edge_attr.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2d = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Delivery To distributor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = len(d2d)\n",
    "node_feature_sequence = []\n",
    "node_target_sequence = []\n",
    "for i in range(duration-1):\n",
    "    node_features = []\n",
    "    node_targets = []\n",
    "    for n,d in G_processed.nodes(data=True):\n",
    "        node_features.append([d['delivered'][i][0],d['sales_order'][i][0],d['factory issue'][i][0]])\n",
    "        node_targets.append(d['production'][i+1])\n",
    "    node_feature_sequence.append(np.array(node_features))\n",
    "    node_target_sequence.append(np.array(node_targets))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 40, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(node_feature_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(node_target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(G_processed.edges())).transpose().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal,DynamicGraphTemporalSignal\n",
    "\n",
    "data_iter = StaticGraphTemporalSignal(\n",
    "    edge_index= np.array(list(G_processed.edges())).transpose(),\n",
    "    edge_weight = edge_attr,\n",
    "    features = node_feature_sequence,\n",
    "    targets = node_target_sequence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "train, test = temporal_signal_split(data_iter, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time, snapshot in enumerate(train):\n",
    "    print(snapshot.x.shape)\n",
    "    print(snapshot.edge_index.shape)\n",
    "    print(snapshot.edge_attr.shape)\n",
    "    print(snapshot.num_nodes)\n",
    "    print(snapshot.num_edge_features)\n",
    "    print(snapshot.y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "class GRU(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(GRU, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 3)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = GRU(node_features=3,filters=1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for time, snapshot in enumerate(train):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = torch.mean((y_hat-snapshot.y)**2)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = []\n",
    "true = []\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    pred.append(y_hat.detach().numpy())\n",
    "    true.append(snapshot.y)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "cost = cost / (time+1)\n",
    "cost = cost.item()\n",
    "print(\"RMSE: {:.4f}\".format(cost**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "221 - 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_r = np.reshape(pred,np.shape(true))\n",
    "true = np.array(true)\n",
    "node_names = [n  for n in G.nodes]\n",
    "for i in range(40):\n",
    "    node = node_names[i]\n",
    "    plt.plot(production[node])\n",
    "    plt.plot(x = range(176,221),y= pred_r[:,i])\n",
    "    plt.plot(x = range(176,221),y=true[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supplychain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
