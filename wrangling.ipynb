{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Graph Structure</h3>\n",
    "\n",
    "<h4> Nodes </h4>\n",
    "\n",
    "represent a product\n",
    "\n",
    "Node features:\n",
    "* *production* - quantifies product output considering sales orders, customer demand, vehicle fill rate, and delivery urgency.\n",
    "* *sales order* - signifies distributor-requested quantities, pending approval from the accounts department.\n",
    "* *delivered* - denotes products dispatched to distributors.\n",
    "* *factory issue* - covers total products with issues shipped from manufacturing facilities, with some going to distributors and the rest to storage warehouses.\n",
    "\n",
    "\n",
    "\n",
    "<h4> Edges </h4>\n",
    "\n",
    "represent relations between products\n",
    "\n",
    "Edge features:\n",
    "* *GroupCode* :         1 or 0, if products are in the same product group\n",
    "* *SubGroupCode* :      1 or 0, if products are in the same product sub-group\n",
    "* *Plant* :             Number of plants in common\n",
    "* *Storage Location* :  Number of Storage Locations in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv('Raw Dataset/Homogenoeus/Nodes/Node Types (Product Group and Subgroup).csv')\n",
    "\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(nodes['Node'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group_edges(path):\n",
    "    \"\"\"adds edges and edge features for groupcode and subgroupcode\"\"\" \n",
    "    df = pd.read_csv(path)\n",
    "    edge_type = [col for col in df.columns if col[:4] != 'node'][0]\n",
    "    md = [{edge_type:1} for product in df[edge_type]]\n",
    "    G.add_edges_from(zip(df['node1'],df['node2'],md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_other_edges(path):\n",
    "    \"\"\"adds edges and edge features for Plants and Storage Locations\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    edge_type = [col for col in df.columns if col[:4] != 'node'][0]\n",
    "    node1 = df['node1'].to_list()\n",
    "    node2 = df['node2'].to_list()\n",
    "    pairs = [set(t) for t in zip(node1,node2)]\n",
    "    distinct_pairs = []\n",
    "    pair_counts = []\n",
    "\n",
    "    while len(pairs) > 0:\n",
    "        p = pairs[0]\n",
    "        distinct_pairs.append(p)\n",
    "        n = pairs.count(p)\n",
    "        pair_counts.append(n)\n",
    "\n",
    "        for i in range(n):\n",
    "            pairs.remove(p)\n",
    "    \n",
    "    edges = [tuple(s) + ({edge_type:pair_counts[i]},) for i,s in enumerate(distinct_pairs)]\n",
    "    G.add_edges_from(edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_other_edges('Raw Dataset/Homogenoeus/Edges/Edges (Plant).csv')\n",
    "add_group_edges('Raw Dataset/Homogenoeus/Edges/Edges (Product Group).csv')\n",
    "add_group_edges('Raw Dataset/Homogenoeus/Edges/Edges (Product Sub-Group).csv')\n",
    "add_other_edges('Raw Dataset/Homogenoeus/Edges/Edges (Storage Location).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in attributes on edges where its missing\n",
    "\n",
    "for node1, node2 in G.edges:\n",
    "    edge_keys = G[node1][node2].keys()\n",
    "    for edge_type in ['Plant','GroupCode','SubGroupCode','Storage Location']:\n",
    "        if not edge_type in edge_keys:\n",
    "            G[node1][node2][edge_type] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2d = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Delivery To distributor.csv')\n",
    "factory_issue = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Factory Issue.csv')\n",
    "production = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Production .csv')\n",
    "sales_orders = pd.read_csv('Raw Dataset/Homogenoeus/Temporal Data/Weight/Sales Order .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_orders.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "noticed a lot of zeros so I'm going to check on the proportion of zeros for all the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal = [d2d,factory_issue,production,sales_orders]\n",
    "names = ['delivery','factory issue','production','sales']\n",
    "inspect = {\n",
    "\n",
    "}\n",
    "\n",
    "for i,feat in enumerate(temporal):\n",
    "    zeros = [len(feat[feat[col] == 0])/len(feat) for col in nodes['Node']]\n",
    "    inspect[names[i]] = zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(inspect,index=nodes['Node'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed 12 products as they had almost all zero values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_nodes_from(['EEA200G24P','EEA500G12P','MAC1K25P','MAP1K25P','MAPA1K24P','ATPA1K24P','ATPPCH5X5K','POP015K',\n",
    "                     'SO0005L04P','SO0002L09P',\t'SO0001L12P','SO0500M24P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding temporal data as node features\n",
    "\n",
    "for node in G.nodes: \n",
    "    G.nodes[node]['delivered'] = d2d[node].to_numpy()\n",
    "    G.nodes[node]['factory issue'] = factory_issue[node].to_numpy()\n",
    "    G.nodes[node]['sales_order'] = sales_orders[node].to_numpy()\n",
    "    G.nodes[node]['production'] = production[node].to_numpy()\n",
    "    G.nodes[node]['GroupCode'] = nodes[nodes['Node'] == node]['Group'].iloc[0] #feature added for exploratory purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(G,open('graphs/graph.pkl','wb')) #Collab and collab pro\n",
    "                                             #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
